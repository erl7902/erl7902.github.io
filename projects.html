<!DOCTYPE html>
<html>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<head>
<link rel="stylesheet" type="text/css" href="styles.css">
</head>

<body>
  <div class="page">
    <div class="navbar">
    <ul class="navbar">
      <li class="navbar-li"><a a class="navbar-li-a" href="index.html">Home</a></li>
      <li class="navbar-li"><a a class="navbar-li-a" href="about.html">About</a></li>
      <li class="navbar-li"><a a class="navbar-active" href="projects.html">Projects</a></li>
      <li class="navbar-li"><a a class="navbar-li-a" href="contact.html">Contact</a></li>
    </ul>
  </div>

  <div class="content">
    <h2> Projects </h2>
    <p>While at Smartvid, one project I was responsible for was the automation
    of what was a painfully manual task for our sales team. I created a new
    pipeline for data to flow from the database, be transformed in Python to
    generate the appropriate statistics and metrics, and was deposited in
    Google Drive as a CSV for easy access.</p>
    <p>My Master's thesis was on understanding the moderation of online scientific
    discourse. I created a lightweight website in Flask (python) and MySQL to
    collect data from moderators of the <i>/r/science</i> community on reddit.
    Participants were asked to determine whether a given comment posted to
    <i>/r/science</i> should be permitted, and to explain why. I was able to
    obtain a deeper understanding of the standards to which the moderators held
    the community to, and how the moderators go about their work. This expertly
    labeled data was used alongside a larger set of reddit comments to train a
    neural network and several traditional models (SVC, DT, GB) on the task of
    moderating <i>/r/science</i> comments. I was able to obtain an accuracy
    similar to the inter-annotator agreement, suggesting that automated moderation
    can be used to assist human moderators.</p>

    <p>
    More to come - this page is a work in progress!
    </p>

    <h2> Publications </h2>

    <p> E. Lucas, C. O. Alm and R. Bailey, "Understanding Human and Predictive Moderation of Online Science Discourse," 2019 IEEE Western New York Image and Signal Processing Workshop (WNYISPW), Rochester, NY, USA, 2019, pp. 1-5, doi: 10.1109/WNYIPW.2019.8923109. </p>

    <p>Elizabeth Lucas. Interstitial content detection. arXiv preprint.
      arXiv: 1708.04879, 2017 </p>

  </div>

  </div>
</body>
</html>
